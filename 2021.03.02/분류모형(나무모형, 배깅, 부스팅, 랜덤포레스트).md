# ⭕ 의사결정나무

R에서는 의사결정나무 모형을 tree, ctree와 rpart 함수를 통해 분석을 수행할 수 있다. tree함수는 불순도의 측도로 엔트로피 지수를 사용하며, ctree의 경우 별로도 가지치기할 필요는 없지만, 입력 변수는 31개까지만 가능하다.   

rpart함수는 CART(Classification and Regression Trees)방법을 사용한다.

```R
library(rpart) # 패키지 로드
install.packages('rpart.plot')
library(rpart.plot) # 그림을 그릴 패키지 로드

dt_model = rpart(credit.rating ~., # 모형 수행
                 method = 'class',
                 data = train,
                 control = rpart.control(maxdepth = 5,
                                         minsplit = 15))
prp(dt_model, type = 4, extra = 2) # 나무모형 결과

dt_model$cptable # cptable을 통해 교차타당성 오차 제공
# nsplit은 분할 횟수, xerror는 해당 cp에서 cross validation했을 때 오류율, xstd는 해당 cp에서 cross validation 했을 때 편차,
# 일반적으로 xerror가 가장 낮은 split의 갯수를 선택한다.
```

```R
> dt_model$cptable
          CP nsplit rel error    xerror       xstd
1 0.05365854      0 1.0000000 1.0000000 0.05873225
2 0.04390244      3 0.8341463 1.0341463 0.05930277
3 0.03414634      4 0.7902439 1.0390244 0.05938153
4 0.01000000      5 0.7560976 0.9463415 0.05776613
```

위 결과를 통해 xerror가 가장은 nsplit인 5에서 나무모형을 선택한다. 또한 나무모형은 총 2번 분할한다.

```R
pred_dt = predict(dt_model, test[,-1], type = "class") # 예측값을 'class'로 지정하여 분류 그룹을 출력
confusionMatrix(data=pred_dt, reference = test[,1], positive = '1')
```

```R
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0  42  21
         1  53 184
                                          
               Accuracy : 0.7533          
                 95% CI : (0.7005, 0.8011)
    No Information Rate : 0.6833          
    P-Value [Acc > NIR] : 0.0047614       
                                          
                  Kappa : 0.3734          
                                          
 Mcnemar's Test P-Value : 0.0003137       
                                          
            Sensitivity : 0.8976          
            Specificity : 0.4421          
         Pos Pred Value : 0.7764          
         Neg Pred Value : 0.6667          
             Prevalence : 0.6833          
         Detection Rate : 0.6133          
   Detection Prevalence : 0.7900          
      Balanced Accuracy : 0.6698          
                                          
       'Positive' Class : 1
```

Accuracy는 0.7533이며, 민감도는 0.8976으로 높게 계산되었다. 또한 특이도는 0.4421이다.

```R
pred_dt_roc = prediction(as.numeric(pred_dt), as.numeric(test[,1]))
plot(performance(pred_dt_roc, 'tpr','fpr')) # ROC 커브 작성
abline(a = 0, b = 1, lty = 2, col = 'black') # y = x 선
```

```R
> performance(pred_dt_roc, 'auc')@y.values # AUC 값 확인 @y.values로 확인가능
[[1]]
[1] 0.6698331
```

앞서 시행했던 iris 데이터를 나무모형으로 분석한다면, 다음과 같다.

```R
library(caret)
dt_model2 = rpart(Species~., data = train_iris)
prp(dt_model2, type = 4, extra = 2)
pred_dt2 = predict(dt_model2, test_iris[,-5], type = 'class')
confusionMatrix(data = pred_dt2, reference = test_iris[,5])
> Confusion Matrix and Statistics

            Reference
Prediction   setosa versicolor virginica
  setosa         15          0         0
  versicolor      0         10         1
  virginica       0          0        19

Overall Statistics
                                          
               Accuracy : 0.9778          
                 95% CI : (0.8823, 0.9994)
    No Information Rate : 0.4444          
    P-Value [Acc > NIR] : 8.12e-15        
                                          
                  Kappa : 0.9656          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: setosa Class: versicolor
Sensitivity                 1.0000            1.0000
Specificity                 1.0000            0.9714
Pos Pred Value              1.0000            0.9091
Neg Pred Value              1.0000            1.0000
Prevalence                  0.3333            0.2222
Detection Rate              0.3333            0.2222
Detection Prevalence        0.3333            0.2444
Balanced Accuracy           1.0000            0.9857
                     Class: virginica
Sensitivity                    0.9500
Specificity                    1.0000
Pos Pred Value                 1.0000
Neg Pred Value                 0.9615
Prevalence                     0.4444
Detection Rate                 0.4222
Detection Prevalence           0.4222
Balanced Accuracy              0.9750
```

# ⭕ 앙상블

앙상블 기법은 주어진 자료로부터 여러 개의 예측모형들을 만든 후 예측모형들을 조합하여 하나의 최종 예측모형을 만드는 방법이다. 학습방법이 가장 불안정한 의사결정나무에 주로 이용한다.   

가장 대표적인 방법에는 배깅(Bagging)과 부스팅(Boosting)이 있다. 참고로 랜덤포레스트(Random forest)는 배깅의 개념과 feature(변수)의 임의 선택(Random Selection)을 결합한 앙상블 기법이다.

## ❗ 배깅(Bagging)

주어진 자료에서 여러 개의 붓스트랩(Bootstrap) 자료를 생성하고 각 붓트스랩 자료에 예측모형을 만든 후 결합하여 최종 예측모형을 만드는 방법이다.   

보팅(Voting)은 여러 개의 모형으로부터 산출된 결과 중 다수결에 의해서 최종 결과를 선정하는 과정이다.   

최적의 의사결정나무를 구축할 때 가장 어려운 부분이 가지치기(Pruning)이지만, 배깅에서는 가지치기를 하지 않고 최대로 성장한 의사결정나무들을 활용한다.   

훈련자료의 모집단의 분포를 모르기 때문에 실제 문제에서는 평균예측모형을 구할 수 없다. 배깅은 이러한 문제를 해결하기 위해 훈련자료를 모집단으로 생각하고 평균예측모형을 구하여 분산을 줄이고 예측력을 향상시킬 수 있다.   

R에서 bagging 분석을 위한 함수는 adabag 패키지의 bagging 함수이며 이를 이용하여 분류분석을 실시할 수 있다.

```R
library(adabag)
bag = bagging(credit.rating~., # 분류할 변수
              data = train, # data
              mfinal = 15) # 반복 또는 트리의 갯수는 15
names(bag) # bagging에 의해 생성된 결과들 확인
bag$importance # 중요도 파악

library(caret)
pred_bg = predict(bag, test, type= "class") # 
confusionMatrix(data = as.factor(pred_bg$class), # as.factor를 사용한 이유는 pred_bg$class가 수치형 자료이기 때문임
                reference = test$credit.rating,
                positive = '1')

Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0  44  22
         1  51 183
                                         
               Accuracy : 0.7567         
                 95% CI : (0.704, 0.8041)
    No Information Rate : 0.6833         
    P-Value [Acc > NIR] : 0.003235       
                                         
                  Kappa : 0.3876         
                                         
 Mcnemar's Test P-Value : 0.001049       
                                         
            Sensitivity : 0.8927         
            Specificity : 0.4632         
         Pos Pred Value : 0.7821         
         Neg Pred Value : 0.6667         
             Prevalence : 0.6833         
         Detection Rate : 0.6100         
   Detection Prevalence : 0.7800         
      Balanced Accuracy : 0.6779         
                                         
       'Positive' Class : 1 
```

```R
pred_bg_roc = prediction(as.numeric(pred_bg$class), as.numeric(test[,1]))
plot(performance(pred_bg_roc, 'tpr', 'fpr'))
abline(a = 0, b = 1, lty = 2, col = "black")
performance(pred_bg_roc, 'auc')@y.values
> performance(pred_bg_roc, 'auc')@y.values
[[1]]
[1] 0.6779204
```

## ❗ 부스팅(Boosting)

예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법으로 Adaboost는 이진분류 문제에서 랜덤 분류기보다 조금 더 좋은 분류기 n개에 각각 가충치를 설정하고 n개의 분류기를 결합하여 최종 분류기를 만든느 방법을 제안함. (각 가중치의 총합은 1)   

훈련오차를 빠르고 쉽게 줄일 수 있으며, 배깅에 비해 많은 경우 예측오차가 향상되어 Adaboost의 성능이 bagging보다 뛰어난 경우가 많다.   

R에서는 Boosting 분석을 수행할 수 있는 함수로 adabag의 boosing 함수이다.

```R
boost = boosting(credit.rating ~., # 예측할 변수
                 data = train, # 데이터
                 boos =TRUE, # 샘플가중치 여부 샘플에 따른 가중치 부여 TRUE, 모두 동일한 가중치는 FALSE
                 mfinal = 80) # 반복또는 트리 수
names(boost)

boost$importance # 중요도 판단

library(caret)
pred_boos = predict(boost, test, type = "class") # 만든 모형으로 예측하기
confusionMatrix(as.factor(pred_boos$class),
                reference = test$credit.rating,
                positive = '1')

library(ROCR)
pred_boos_roc = prediction(as.numeric(pred_boos$class), as.numeric(test[,1]))
plot(performance(pred_boos_roc, 'tpr','fpr'))
abline(a = 0, b = 1, lty = 2, col = "black")

performance(pred_boos_roc, 'auc')@y.values
```

# ⭕ 랜덤 포레스트

의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 과정이다.   

R에서는 randomForest 패키지로 구현가능하다. randomForest 함수를 사용하고 random input에 따른 forest of tree를 생성하여 이를 이용한 분류를 한다.   

수천개의 변수를 통해 변수 제거 없이 실행되므로 정확도 측면에서 좋은 성과를 보인다.   

이론적 설명이나 최종 결과에 대한 해석이 어렵다는 단점이 있지만, 예측력이 매우 높은 것으로 알려져있다.  특히 입력변수가 많은 경우, 배깅과 부스팅과 비슷하거나 좋은 예측력을 보인다.   

```R
rf_model = randomForest(credit.rating~., # 예측 및 분류할 변수
                        data = train, # 데이터셋
                        ntree = 50, # 사용할 트리 수, 적당히 크게 입력
                        mtry = sqrt(20), # 각 분할에서 램덤으로 뽑힌 변수의 개수 보통 classification은 sqrt(변수의 갯수), regression은 변수의 갯수/3
                        importance = T)
rf_model
Call:
 randomForest(formula = credit.rating ~ ., data = train, ntree = 50,      mtry = sqrt(20), importance = T) 
               Type of random forest: classification
                     Number of trees: 50
No. of variables tried at each split: 4

        OOB estimate of  error rate: 24.71%
Confusion matrix:
   0   1 class.error
0 86 119   0.5804878
1 54 441   0.1090909
```

```R
pred_rf_model = predict(rf_model,
                        test[,-1],
                        type = 'class')

confusionMatrix(pred_rf_model, 
                reference = test[,1],
                positive = '1')
                Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0  42  17
         1  53 188
                                          
               Accuracy : 0.7667          
                 95% CI : (0.7146, 0.8134)
    No Information Rate : 0.6833          
    P-Value [Acc > NIR] : 0.0009172       
                                          
                  Kappa : 0.3998          
                                          
 Mcnemar's Test P-Value : 2.873e-05       
                                          
            Sensitivity : 0.9171          
            Specificity : 0.4421          
         Pos Pred Value : 0.7801          
         Neg Pred Value : 0.7119          
             Prevalence : 0.6833          
         Detection Rate : 0.6267          
   Detection Prevalence : 0.8033          
      Balanced Accuracy : 0.6796          
                                          
       'Positive' Class : 1 
```

```R
pred_rf_roc = prediction(as.numeric(pred_rf_model),
                         as.numeric(test[,1]))
plot(performance(pred_rf_roc, 'tpr', 'fpr'))
abline(a = 0, b = 1, lty = 2, col = 'black')
performance(pred_rf_roc, 'auc')@y.values
[[1]]
[1] 0.6824134
```

iris 데이터를 이용한 randomForest

```R
rf_model2 = randomForest(Species~.,
                         data = train_iris,
                         ntree = 50,
                         mtry = sqrt(4),
                         importance = T)
rf_model2

pred_rf_model2 = predict(rf_model2,
                         data = test_iris[,-5],
                         type = 'class')
confusionMatrix(data = pred_rf_model2,
                reference = test_iris[,5],
                positive = '1')
```

