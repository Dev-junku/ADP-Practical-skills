# ⭕ ADP 모의고사 1회

## 1️⃣ 01 정형 데이터 마이닝 lotto

### 1) 연관규칙을 위해 `lotto `데이터셋을 `transaction` 데이터로 변환하시오. (단, 로또번호가 추첨된 순서는 고려하지 않음) 그리고 변환된 데이터에서 가장 많이 등장한 10개의 번호를 순서대로 출력하고 이를 설명하시오.

`transaction` 데이터로 변환하기 위해서는 `as()`를 사용하여 변환할 수 있음. 하지만 이것만 알면 안되고 현재 `lott`o라는 데이터 셋이 어떻게 되어 있는지 알아야함. `lotto`는 `time_id` 로또회차, `numM` 해당 회의 N번 째 당첨번호 6개로 총 7개의 열과 859개의 행으로 이루어져있음. 따라서 각 해당 회차에는 6개의 열로 번호가 표현되어 있음. 이를 하나로 통합한 후 집합처럼 묶어줄것임 이를 위해 `reshape2` 패키지의 `melt()`함수와 `split()`함수를 사용

```R
lotto = read.table('clipboard', sep='\t', header=T)
head(lotto)
  time_id num1 num2 num3 num4 num5 num6
1     859    8   22   35   38   39   41
2     858    9   13   32   38   39   43
3     857    6   10   16   28   34   38
4     856   10   24   40   41   43   44
5     855    8   15   17   19   43   44
6     854   20   25   31   32   36   43

str(lotto)
'data.frame':	859 obs. of  7 variables:
 $ time_id: int  859 858 857 856 855 854 853 852 851 850 ...
 $ num1   : int  8 9 6 10 8 20 2 11 14 16 ...
 $ num2   : int  22 13 10 24 15 25 8 17 18 20 ...
 $ num3   : int  35 32 16 40 17 31 23 28 22 24 ...
 $ num4   : int  38 38 28 41 19 32 26 30 26 28 ...
 $ num5   : int  39 39 34 43 43 36 27 33 31 36 ...
 $ num6   : int  41 43 38 44 44 43 44 35 44 39 ...

# 연관분석을 위한 transaction 데이터 만들기
ibrary(reshape2) # 업로드
lot_melt = melt(lotto, id.vars=1) # 1열을 기준으로 나머지 열을 전부 하나의 열로 맞추기
lot_melt2 = lot_melt[,-2] # 2번째 열은 variable이므로 의미가 없음
str(lot_melt2) # 구조 확인
'data.frame':	5154 obs. of  2 variables:
 $ time_id: int  859 858 857 856 855 854 853 852 851 850 ...
 $ value  : int  8 9 6 10 8 20 2 11 14 16 ...

library(arules) # as함수를 사용하기 위해 라이브러리 업로드
lot_sp = split(lot_melt2$value, lot_melt2$time_id) # id를 기준으로 구분 짓고 하나로 통합
lot_ts = as(lot_sp, 'transactions') # transactions 데이터로 전환
inspect(lot_ts) # transactions 데이터를 출력하기 위해서 inspect 함수를 사용
      items               transactionID
[1]   {10,23,29,33,37,40} 1            
[2]   {9,13,21,25,32,42}  2            
[3]   {11,16,19,21,27,31} 3            
[4]   {14,27,30,31,40,42} 4            
[5]   {16,24,29,40,41,42} 5            
[6]   {14,15,26,27,40,42} 6            
[7]   {2,9,16,25,26,40}   7            
[8]   {8,19,25,34,37,39}  8            
[9]   {2,4,16,17,36,39}   9            
[10]  {9,25,30,33,41,44}  10
# 상위 10개의 로또 번호를 확인

itemFrequencyPlot(lot_ts, topN=10, type='absolute') # 절대도수를 기준으로 파악
itemFrequencyPlot(lot_ts, topN=10) # 상대도수를 기준으로 파악

```

![lot_ts](.\img\lot_ts.png)

유독 34라는 수가 높은 비율로 등장한 것을 확인할 수 있으며 나머지 수에서 큰 비율의 차이가 있지는 않음

### 2) 변환한 데이터에 대해 `apriori()` 함수를 사용하여 다음 괄호 안의 조건을 반영하여 연관규칙을 생성하고, 이를 `'rules_1'`라는 변수에 저장하여 결과를 해석하시오. (최소지지도:0.002, 최소신뢰도:0.8, 최소조합 항목 수:2, 최대조합 항목 수:6)그리고 도출된 연관규칙들을 향상도를 기준으로 내림차순 정렬하여 상위 30개의 규칙을 확인하고 이를 데이터 프레임 형태로 반환하여 CSV파일로 출력하시오

```R
# 연관분석 수행
metric_params = list(supp=0.002, conf=0.8, minlen=2, maxlen=6) # parameter list생성
rule_1 = apriori(lot_ts, parameter = metric_params) # apriori()를 이용해서 결과 생성, -> 총 679개의 데이터가 생성되었다.
inspect(rule_1[1:20,]) # 해당 규칙 20개만 확인 
     lhs           rhs  support     confidence lift     count
[1]  {9,32,43}  => {38} 0.002328289 1          7.601770 2    
[2]  {9,38,43}  => {32} 0.002328289 1          8.855670 2    
[3]  {32,38,43} => {9}  0.002328289 1          9.651685 2    
[4]  {9,23,28}  => {7}  0.002328289 1          7.535088 2    
[5]  {7,9,23}   => {28} 0.002328289 1          8.180952 2    
[6]  {7,9,28}   => {23} 0.002328289 1          8.676768 2    
[7]  {7,23,28}  => {9}  0.002328289 1          9.651685 2    
[8]  {9,23,35}  => {18} 0.002328289 1          7.099174 2    
[9]  {9,18,23}  => {35} 0.002328289 1          8.103774 2    
[10] {9,18,35}  => {23} 0.002328289 1          8.676768 2    
[11] {18,23,35} => {9}  0.002328289 1          9.651685 2    
[12] {1,9,23}   => {12} 0.002328289 1          6.983740 2    
[13] {5,9,30}   => {43} 0.002328289 1          6.872000 2    
[14] {9,30,43}  => {5}  0.002328289 1          7.218487 2    
[15] {6,9,28}   => {1}  0.002328289 1          7.040984 2    
[16] {9,21,29}  => {1}  0.002328289 1          7.040984 2    
[17] {9,17,29}  => {1}  0.002328289 1          7.040984 2    
[18] {9,27,29}  => {40} 0.002328289 1          6.817460 2    
[19] {9,29,40}  => {27} 0.002328289 1          6.817460 2    
[20] {9,27,40}  => {29} 0.002328289 1          8.103774 2 

# lift를 기준으로 규칙을 내림차순 정렬한 후, 30개의 규칙을 확인
rule_2 = sort(rule_1, by = 'lift', decreasing = T)
inspect(rule_2[1:30,])
     lhs              rhs  support     confidence lift     count
[1]  {32,38,43}    => {9}  0.002328289 1          9.651685 2    
[2]  {7,23,28}     => {9}  0.002328289 1          9.651685 2    
[3]  {18,23,35}    => {9}  0.002328289 1          9.651685 2    
[4]  {14,17,33}    => {9}  0.002328289 1          9.651685 2    
[5]  {7,23,29}     => {22} 0.002328289 1          9.336957 2    
[6]  {10,27,42}    => {22} 0.002328289 1          9.336957 2    
[7]  {25,31,45}    => {22} 0.002328289 1          9.336957 2    
[8]  {21,26,37}    => {22} 0.002328289 1          9.336957 2    
[9]  {24,36,38}    => {22} 0.002328289 1          9.336957 2    
[10] {7,24,31}     => {22} 0.002328289 1          9.336957 2    
[11] {7,31,34}     => {22} 0.002328289 1          9.336957 2    
[12] {33,36,37}    => {22} 0.002328289 1          9.336957 2    
[13] {10,34,36}    => {22} 0.002328289 1          9.336957 2    
[14] {10,34,36,44} => {22} 0.002328289 1          9.336957 2    
[15] {7,24,31,34}  => {22} 0.002328289 1          9.336957 2    
[16] {9,38,43}     => {32} 0.002328289 1          8.855670 2    
[17] {14,29,33}    => {32} 0.002328289 1          8.855670 2    
[18] {14,36,42}    => {32} 0.002328289 1          8.855670 2    
[19] {3,24,45}     => {32} 0.002328289 1          8.855670 2    
[20] {3,13,31}     => {32} 0.002328289 1          8.855670 2    
[21] {3,12,18}     => {32} 0.002328289 1          8.855670 2    
[22] {3,18,40}     => {32} 0.002328289 1          8.855670 2    
[23] {10,18,31}    => {32} 0.002328289 1          8.855670 2    
[24] {17,18,31}    => {32} 0.002328289 1          8.855670 2    
[25] {17,33,34}    => {32} 0.003492433 1          8.855670 3    
[26] {7,9,28}      => {23} 0.002328289 1          8.676768 2    
[27] {9,18,35}     => {23} 0.002328289 1          8.676768 2    
[28] {28,30,44}    => {23} 0.002328289 1          8.676768 2    
[29] {25,38,42}    => {23} 0.002328289 1          8.676768 2    
[30] {18,21,39}    => {23} 0.002328289 1          8.676768 2 

rule_2 = as(rule_2, 'data.frame') # data.frame으로 만들기

# 문제의 조건처럼 csv파일로 저장
write.csv(rule_2, file='___')
```

우선 로또의 경우 대표적인 독립적인 확률이기 때문에 아무런 연관성이 없을 것으로 생각이 크지만, 연관분석 결과 lift값이 생각보다 높게 측정되었음을 알 수 있다. 하지만, 지지도의 값이 0.002(0.2%)보다 약간 큰 값으로 역시 매우 연관성이 없을 알 수 있다.

### 3) 생성된 연관규칙 `'rules_1'`에 대한 정보를 해석하고 , 1)번 문제를 통해 확인했을 때 가장 많이 추첨된 번호가 우측항에 존재하는 규칙들만을 'rules_most_freq'라는 변수에 저장하고 해당 규칙들을 해석하여 인사이트를 도출하시오.

```R
# rule_1의 정보를 summary()함수로 요약
summary(rule_1)
set of 679 rules

rule length distribution (lhs + rhs):sizes
  4   5 
632  47 

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  4.000   4.000   4.000   4.069   4.000   5.000 

summary of quality measures:
    support           confidence      lift           count      
 Min.   :0.002328   Min.   :1    Min.   :6.410   Min.   :2.000  
 1st Qu.:0.002328   1st Qu.:1    1st Qu.:7.041   1st Qu.:2.000  
 Median :0.002328   Median :1    Median :7.280   Median :2.000  
 Mean   :0.002364   Mean   :1    Mean   :7.434   Mean   :2.031  
 3rd Qu.:0.002328   3rd Qu.:1    3rd Qu.:7.670   3rd Qu.:2.000  
 Max.   :0.003492   Max.   :1    Max.   :9.652   Max.   :3.000  
mining info:
   data ntransactions support confidence
 lot_ts           859   0.002        0.8
# 679개의 연관규칙분석이 도출되었으며, 그 중 632개의 규칙은 4개의 로또번호로 구성
# 47개의 규칙은 5개의 번호로 구성되어 있음
# 향상도의 최소값은 6.410으로 꽤 높으며
# 지지도의 평균값은 0.002364로 같이포함될 확률이 1%도 되지 않음

rule_most_freq = subset(rule_1,rhs %in% '34')
inspect(rule_most_freq)
# 19개의 규칙이 도출
# 1번의 규칙 살펴보면 7, 22, 31이 뽑힌난 뒤에 34개 뽑힐 지지도는 0.002328289로 0.2%를 이야기하고 있다.
# 여기서 향상도 값이 6.4 이상으로 높은 값을 유지하고 있으나,
# 본 연관 분석의 문제는 단순히 조합에 의한 연관성을 분석했다는 것에 의해
# 분 분석에서 높은 확률로 나타날 조합이 꼭 로또 번호가 되는 것은 아니다.
```

## 2️⃣ 통계분석 FIFA 추후.. 수정..

